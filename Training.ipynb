{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import errno\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "from fastai.text import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data structuring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to split our data up into training and validation sets (TODO: Strip out duplicates - different keys is ok though)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_ALL = Path('data/encoded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_DIR = Path('data/split')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_dir_exists(path):\n",
    "    \"\"\" Ensure that a directory at the given path exists \"\"\"\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_fnames = [encoded for encoded in os.listdir(DATA_DIR_ALL)]\n",
    "# RANDOM_SEED = 42\n",
    "# random.Random(RANDOM_SEED).shuffle(all_fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_set = all_fnames[: int(len(all_fnames) * 0.8)]\n",
    "# validation_set = all_fnames[len(training_set):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for set_dir, data in zip(('train', 'valid'), (training_set, validation_set)):\n",
    "#     ensure_dir_exists(OUT_DIR/set_dir)\n",
    "#     for fname in data:\n",
    "#         shutil.copy(DATA_DIR_ALL/fname, OUT_DIR/set_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = OUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB = [f'S-{i}' for i in range(24, 76)] + ['R']\n",
    "len(VOCAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a very limited 'vocabulary' of musical tokens. Tokenization simply involves splitting the comma-delimited list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIDISeqTokenizer(BaseTokenizer):\n",
    "    def tokenizer(self, text):\n",
    "        return text.split(',')\n",
    "    \n",
    "class CustomTokenizer(Tokenizer):\n",
    "    \"Put together rules and a tokenizer function to tokenize text with multiprocessing.\"\n",
    "    def __init__(self, lang:str='en', pre_rules:ListRules=None,\n",
    "                 post_rules:ListRules=None, special_cases:Collection[str]=None, n_cpus:int=None):\n",
    "        super().__init__(tok_func=MIDISeqTokenizer, pre_rules=[], post_rules=[], special_cases=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = TextLMDataBunch.from_folder(DATA_DIR, tokenizer=CustomTokenizer(), include_bos=False, include_eos=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm.save('data_lm_export.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm = load_data(DATA_DIR, 'data_lm_export.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.381596</td>\n",
       "      <td>0.347482</td>\n",
       "      <td>0.901480</td>\n",
       "      <td>09:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.5, pretrained=False)\n",
    "learn.fit_one_cycle(1, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('model_v1_1_epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S-40 H-40 S-42 S-60 S-67'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict('S-40 H-40 S-42 S-60')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seq(start, learner, length=32):\n",
    "    seq = start\n",
    "    while len(seq.split(' ')) < length:\n",
    "        seq = learner.predict(seq)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S-27 H-27 S-25 S-60 S-67 S-60 S-62 S-67 H-50 S-62 S-65 S-60 S-58 S-67 S-62 S-60 S-67 S-60 S-67 S-67 S-63 H-60 H-39 H-54 S-67 S-35 S-67 S-62 S-24 S-52 S-60 S-43'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_seq('S-27 H-27', learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn.load('model_v1_1_epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.343286</td>\n",
       "      <td>0.459055</td>\n",
       "      <td>0.881116</td>\n",
       "      <td>09:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.313737</td>\n",
       "      <td>0.275368</td>\n",
       "      <td>0.917603</td>\n",
       "      <td>09:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(2, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('model_v1_3_epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S-60 S-60 S-67 S-60 H-47 S-64 S-60 S-29 S-60 S-67 S-67 S-69 S-67 S-60 S-62 S-60'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_seq('S-60 S-60', learn, length=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
